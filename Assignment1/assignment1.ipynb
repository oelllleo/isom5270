{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comapany Background:\n",
    "\n",
    "Select  Collections,  Inc.,  was  a  start-up  subsidiary  of  a  major credit  card  company\n",
    "\n",
    "***The company  purchased  distressed  consumer  debt  at  discounted  rates from  such  major  credit  card***\n",
    "and  then  \n",
    "used  data-driven  decision-making and dynamic value assessment to optimize the collection processes associated with the purchased accounts\n",
    "\n",
    "For each purchased account, ***the first decision was whether to resell or attempt to collect***. For accounts the company decided to attempt to collect, a host of tactics was available for use in any sequence and with any frequency. \n",
    "\n",
    "Like other collection companies, Select Collections used ***the telephone  and  the  legal  system***  as  its  two  major  collection  tools.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "\n",
    "I want to see if we can ***build a model to predict how much money we will collect from  delinquent  accounts.***  Such  a  model  would  prove  very  useful in  ***deciding which accounts to purchase and how much to pay.***\n",
    "\n",
    "There are ***3,570*** accounts in a data set that I will call the training set\n",
    "\n",
    "***We  purchased  these  accounts  and  then  collected  the  amount  shown  in  the  last column, labeled totalpay.*** \n",
    "Totalpay is the variable of interest. I want you to ***come up with a way to forecast totalpay.***\n",
    "\n",
    "I  want  you  to  use  the  model  you  come  up with to predict totalpay for the 3,570 accounts in a separate worksheet of data that I will call the test set. \n",
    "\n",
    "I  want  an  Excel  file  from  you  containing a single column of numbers. \n",
    "***In cell A1, please put the adjusted R-squared for your model.***\n",
    "***In cells A2 through A3571, put your predicted values for the accounts in the test data set in ID order.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datadict: \n",
    "![alt text](datadict.png \"data dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description:\n",
    "\n",
    "![alt text](description.png \"data description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colume Comparation to total pay\n",
    "\n",
    "![alt text](col_comparasion_totalpay.png \"colume vs totalpay description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Col vs Col description\n",
    "![alt text](col_to_col_relationship.png \"col vs col description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the data\n",
    "#### From data dict :\n",
    "what col should be care?\n",
    "\n",
    "#### from data description:\n",
    "data distrbution is fair ? \n",
    "fair in total\n",
    "rollout is also important ?\n",
    "not fair\n",
    "\n",
    "#### from col to total pay part we now only 4 cols are not well distributed\n",
    "\n",
    "inacscr: The natural log of the ***accessscr***\n",
    "\n",
    "***accessscr***: The account’s accessibility score, an a priori estimation of how likely it is that the accountholder is reached via phone.\n",
    "bureauscr: The output of an in-house prediction model based on the likelihood of receiving payments from the accountholder using credit-bureau attributes as predictors \n",
    "\n",
    "numcalls: The number of telephone calls made (to date) to the accountholder\n",
    "\n",
    "numrpcs: The number of “right-party connects” or phone calls in which the collection agent speaks with the accountholder \n",
    "\n",
    "#### how about col to col ?\n",
    "\n",
    "what grid means to me ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "From ***Understanding the data parts***, already shown the data related accessibility is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pacakge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "labeled_data_file_name = \"Labeled_data.csv\"\n",
    "unlabel_data_file_name = \"Unlabeled_Data.csv\"\n",
    "## load the data \n",
    "col = ['acctid', 'state', 'zip', 'rollout', 'cobal', 'collscr', 'cs', 'accessscr', 'lnacscr', 'bureauscr', 'eaglemod', 'numcalls', 'numrpcs','totalpay']\n",
    "label_data_df = pd.read_csv(labeled_data_file_name)\n",
    "unlabel_data_df = pd.read_csv(unlabel_data_file_name)\n",
    "\n",
    "# Round1 \n",
    "feature_col = ['acctid', 'state', 'zip', 'rollout', 'cobal', 'collscr', 'cs', 'accessscr', 'lnacscr', 'bureauscr', 'eaglemod', 'numcalls', 'numrpcs']\n",
    "\n",
    "\n",
    "## seperate the feature and target\n",
    "features = label_data_df.drop(['acctid', 'totalpay'], axis=1)\n",
    "target = label_data_df['totalpay']\n",
    "## splite the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Labeled_data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['state', 'zip','rollout','cobal','collscr','cs','accessscr','lnacscr','bureauscr','eaglemod','numcalls','numrpcs']]\n",
    "y = data['totalpay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation\n",
    "\n",
    "What algorithm we are using ? at least it support R-squared\n",
    "\n",
    "Linear Regression: Linear regression is a simple and commonly used algorithm that predicts a continuous target variable based on one or more independent variables.\n",
    "\n",
    "Polynomial Regression: Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set: 856513.9636756183\n",
      "Mean Absolute Percentage Error on test set: 358.8362737193568 %\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Labeled_data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['state', 'zip','rollout','cobal','collscr','cs','accessscr','lnacscr','bureauscr','eaglemod','numcalls','numrpcs']]\n",
    "y = data['totalpay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n",
    "X_train_encode = pd.get_dummies(X_train, columns=['state', 'zip', 'rollout', 'collscr'],drop_first=True)\n",
    "\n",
    "## Train the data \n",
    "model = RandomForestRegressor(max_depth=6, min_samples_split=15, min_samples_leaf=5, random_state=1337)\n",
    "model.fit(X_train_encode, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the test set \n",
    "X_test_encode = pd.get_dummies(X_test, columns=['state', 'zip', 'rollout', 'collscr'],drop_first=True)\n",
    "X_test_encode = X_test_encode.reindex(columns=X_train_encode.columns, fill_value=0)\n",
    "predictions = model.predict(X_test_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the stats it is weird. but the model is generate from professor. so no need to do Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as Optimization parts. but having some question on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 : What is the mean absolute percentage error (MAPE) of the predictions made by the deployed model? Enter your answer as a rounded integer. For example, if the MAPE is 20.6%, you should enter 21 (not 0.206)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set: 856513.9636756183\n",
      "Mean Absolute Percentage Error on test set: 358.8362737193568 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error on test set: {mse}\")\n",
    "\n",
    "# Calculate mean squared error\n",
    "msep = mean_absolute_percentage_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Percentage Error on test set: {msep*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 : If we had perfect predictions for totalpay, what decision rule (expressed as an inequality) should we use to decide which accounts to purchase? If the inequality is met, we purchase; otherwise, we do not. For example, you might choose totalpay > 800. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 Apply the decision rule you proposed in the previous question to the test set using the predictions from the deployed model.\n",
    "\n",
    "Q3.1 What percentage of cases indicated a purchase, but actually resulted in a loss? (Enter your answer as a rounded integer (e.g., 82 for 81.64%).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.2 What percentage of cases indicated not to purchase, but actually resulted in missed opportunities? (Enter your answer as a rounded integer (e.g., 82 for 81.64%).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Suppose we want to use this predictive model and decision rule as our data-driven solution to decide which of 3,570 accounts to buy. Based on the test set where you applied this solution, provide a 95% confidence interval for the expected profit. Round your final answer to the nearest 10,000 and express it as integers. For example, if the confidence interval goes from $-32,124.34 to $57,241.32, you would enter -30000 and 60000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Perspective Question\n",
    "\n",
    "Q5 From a business perspective, do you believe this data-driven solution adds value? Please justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 In what follows, you'll work on improving the current solution for selecting accounts to purchase. Choose an appropriate performance measure (e.g., accuracy, precision, recall) to assess your progress. Briefly justify your choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
