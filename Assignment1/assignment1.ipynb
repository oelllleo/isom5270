{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comapany Background:\n",
    "\n",
    "Select  Collections,  Inc.,  was  a  start-up  subsidiary  of  a  major credit  card  company\n",
    "\n",
    "***The company  purchased  distressed  consumer  debt  at  discounted  rates from  such  major  credit  card***\n",
    "and  then  \n",
    "used  data-driven  decision-making and dynamic value assessment to optimize the collection processes associated with the purchased accounts\n",
    "\n",
    "For each purchased account, ***the first decision was whether to resell or attempt to collect***. For accounts the company decided to attempt to collect, a host of tactics was available for use in any sequence and with any frequency. \n",
    "\n",
    "Like other collection companies, Select Collections used ***the telephone  and  the  legal  system***  as  its  two  major  collection  tools.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "\n",
    "I want to see if we can ***build a model to predict how much money we will collect from  delinquent  accounts.***  Such  a  model  would  prove  very  useful in  ***deciding which accounts to purchase and how much to pay.***\n",
    "\n",
    "There are ***3,570*** accounts in a data set that I will call the training set\n",
    "\n",
    "***We  purchased  these  accounts  and  then  collected  the  amount  shown  in  the  last column, labeled totalpay.*** \n",
    "Totalpay is the variable of interest. I want you to ***come up with a way to forecast totalpay.***\n",
    "\n",
    "I  want  you  to  use  the  model  you  come  up with to predict totalpay for the 3,570 accounts in a separate worksheet of data that I will call the test set. \n",
    "\n",
    "I  want  an  Excel  file  from  you  containing a single column of numbers. \n",
    "***In cell A1, please put the adjusted R-squared for your model.***\n",
    "***In cells A2 through A3571, put your predicted values for the accounts in the test data set in ID order.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datadict: \n",
    "![alt text](datadict.png \"data dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description:\n",
    "\n",
    "![alt text](description.png \"data description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colume Comparation to total pay\n",
    "\n",
    "![alt text](col_comparasion_totalpay.png \"colume vs totalpay description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Col vs Col description\n",
    "![alt text](col_to_col_relationship.png \"col vs col description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the data\n",
    "#### From data dict :\n",
    "what col should be care?\n",
    "\n",
    "#### from data description:\n",
    "data distrbution is fair ? \n",
    "fair in total\n",
    "rollout is also important ?\n",
    "not fair\n",
    "\n",
    "#### from col to total pay part we now only 4 cols are not well distributed\n",
    "\n",
    "inacscr: The natural log of the ***accessscr***\n",
    "\n",
    "***accessscr***: The account’s accessibility score, an a priori estimation of how likely it is that the accountholder is reached via phone.\n",
    "bureauscr: The output of an in-house prediction model based on the likelihood of receiving payments from the accountholder using credit-bureau attributes as predictors \n",
    "\n",
    "numcalls: The number of telephone calls made (to date) to the accountholder\n",
    "\n",
    "numrpcs: The number of “right-party connects” or phone calls in which the collection agent speaks with the accountholder \n",
    "\n",
    "#### how about col to col ?\n",
    "\n",
    "what grid means to me ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "From ***Understanding the data parts***, already shown the data related accessibility is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pacakge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "labeled_data_file_name = \"Labeled_data.csv\"\n",
    "unlabel_data_file_name = \"Unlabeled_Data.csv\"\n",
    "## load the data \n",
    "col = ['acctid', 'state', 'zip', 'rollout', 'cobal', 'collscr', 'cs', 'accessscr', 'lnacscr', 'bureauscr', 'eaglemod', 'numcalls', 'numrpcs','totalpay']\n",
    "label_data_df = pd.read_csv(labeled_data_file_name)\n",
    "unlabel_data_df = pd.read_csv(unlabel_data_file_name)\n",
    "\n",
    "# Round1 \n",
    "feature_col = ['acctid', 'state', 'zip', 'rollout', 'cobal', 'collscr', 'cs', 'accessscr', 'lnacscr', 'bureauscr', 'eaglemod', 'numcalls', 'numrpcs']\n",
    "\n",
    "\n",
    "## seperate the feature and target\n",
    "features = label_data_df.drop('totalpay', axis=1)\n",
    "target = label_data_df.drop(feature_col, axis=1)\n",
    "features = data.drop(['acctid', 'totalpay'], axis=1)\n",
    "target = data['totalpay']\n",
    "## splite the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260     1128\n",
       "1805      75\n",
       "3009    2525\n",
       "3288    4080\n",
       "3189     100\n",
       "Name: totalpay, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Labeled_data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['state', 'zip','rollout','cobal','collscr','cs','accessscr','lnacscr','bureauscr','eaglemod','numcalls','numrpcs']]\n",
    "y = data['totalpay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation\n",
    "\n",
    "What algorithm we are using ? at least it support R-squared\n",
    "\n",
    "Linear Regression: Linear regression is a simple and commonly used algorithm that predicts a continuous target variable based on one or more independent variables.\n",
    "\n",
    "Polynomial Regression: Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set: 856513.9636756183\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Labeled_data.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data[['state', 'zip','rollout','cobal','collscr','cs','accessscr','lnacscr','bureauscr','eaglemod','numcalls','numrpcs']]\n",
    "y = data['totalpay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n",
    "X_train_encode = pd.get_dummies(X_train, columns=['state', 'zip', 'rollout', 'collscr'],drop_first=True)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(max_depth=6, min_samples_split=15, min_samples_leaf=5, random_state=1337)\n",
    "model.fit(X_train_encode, y_train)\n",
    "\n",
    "X_test_encode = pd.get_dummies(X_test, columns=['state', 'zip', 'rollout', 'collscr'],drop_first=True)\n",
    "X_test_encode = X_test_encode.reindex(columns=X_train_encode.columns, fill_value=0)\n",
    "predictions = model.predict(X_test_encode)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error on test set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
