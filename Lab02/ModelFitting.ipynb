{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQPZmXxBfs30"
   },
   "source": [
    "# Building and Using Predictive Models\n",
    "\n",
    "\"*It is a capital mistake to theorize before one has data.*\" â€” Sherlock Holmes\n",
    "\n",
    "## Data Preparation: Selecting Variables\n",
    "\n",
    "The first step is to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "SDwYUlzrflqE",
    "outputId": "a5e93766-0bf9-442e-be38-6ea96d9ddf17"
   },
   "outputs": [],
   "source": [
    "# This line imports a library called \"pandas\", a very useful tool to manipulate data with Python. \n",
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV file\n",
    "df1 = pd.read_csv('known_survival.csv')\n",
    "# Print data size\n",
    "print(f\"Total number of rows and columns: {df1.shape}\")\n",
    "# This line displays the top rows in the dataframe.\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejT7dRv9hRBO"
   },
   "source": [
    "This data set contains information about passangers of the Titanic. In this example, we will create a model that predicts the probability of a passsanger surviving the sinking of the Titanic.\n",
    "\n",
    "To do so, we will first keep only the columns that may be related to survival (i.e., all except PassengerId and Name*).\n",
    "\n",
    "\\* Can you think of a reason why this column could potentially be useful to predict survival? If so, make sure to post your answer in the discussion board (this will count as class participation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "jKn_Cg042sCV",
    "outputId": "69d4085e-7671-45a7-a935-7bd8c56b816f"
   },
   "outputs": [],
   "source": [
    "# List of the names of columns\n",
    "cols = ['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "# This selects only the columns that are in 'cols'\n",
    "df2 = df1[cols]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnccocdI8pn8"
   },
   "source": [
    "## Data Preparation: Missing Values\n",
    "\n",
    "We now will address rows with missing values. The best course of action to address missing values will vary from one context to another. The code below illustrates two common alternatives: (1) imputing missing values with some new value (e.g., the mean) and (2) dropping observations with missing values. For simplicity, we will stick to the version of the training data in which the observations with missing values were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRDq3P938iEO",
    "outputId": "9a4abe73-6785-4798-b68f-75750ad967b8"
   },
   "outputs": [],
   "source": [
    "print(\"Number of passengers with missing values for each column:\")\n",
    "print(df2.isna().sum(axis=0))\n",
    "\n",
    "##### OPTION 1: Imputing missing values with the mean\n",
    "df3 = df2.copy()\n",
    "# This replaces the missing values in Age with its average.\n",
    "df3.Age = df2.Age.fillna(df2.Age.mean())\n",
    "# This replaces the missing values in Embarked with its mode.\n",
    "df3.Embarked = df2.Age.fillna(df2.Embarked.mode()[0])\n",
    "print(f\"Observations and columns in the original data set: {df2.shape}\")\n",
    "print(f\"Observations and columns in the new data set: {df3.shape}\")\n",
    "print(df3.isna().sum(axis=0))\n",
    "\n",
    "##### OPTION 2: Dropping observations with missing values\n",
    "# Drop observations with missing values\n",
    "df3 = df2.dropna()\n",
    "print(f\"Observations and columns in the original data set: {df2.shape}\")\n",
    "print(f\"Observations and columns in the new data set: {df3.shape}\")\n",
    "print(df3.isna().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CWIGYuV3n4k"
   },
   "source": [
    "## Data Preparation: Categorical Variables\n",
    "\n",
    "Next, we will do some data pre-processing and transform the existing columns into variables that can be processed by data mining algorithms. More specifically, we will transform categorical variables (variables that represent categories rather than numeric quantities) into dummy variables. Each dummy variable can only take the value 1 or 0 to indicate whether the individual belongs or not to a certain category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "cgZIVXKghCGY",
    "outputId": "c9b3bb72-c31d-45b1-a4dd-b606dad453ed"
   },
   "outputs": [],
   "source": [
    "# The function \"get_dummies\" creates dummy variables for the listed variables\n",
    "df4 = pd.get_dummies(df3, columns=['Pclass', 'Sex', 'Embarked'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating dummy variables, it's also common to drop one of the categories because you only need K-1 binary columns to represent a categorical variable with K categories. You can do that with the `get_dummies` function introduced above by setting the `drop_first` parameter to `TRUE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function \"get_dummies\" creates dummy variables for the listed variables\n",
    "df4 = pd.get_dummies(df3, columns=['Pclass', 'Sex', 'Embarked'], drop_first=True)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISHX2VpW7CRN"
   },
   "source": [
    "Finally, we need to split the data into the variable we want to predict (also known as the target or dependent variable), and the data we want to use to predict (also known as the features or the independent variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbrXYx_u7BPd",
    "outputId": "e6387500-ac9f-4157-9b99-affde206155d"
   },
   "outputs": [],
   "source": [
    "# Name of all the target variable\n",
    "target_variable = 'Survived'\n",
    "# Name of all the columns in df4\n",
    "all_columns = df4.columns.values\n",
    "# Keep the name of all the columns that are not the target variable\n",
    "features = all_columns[all_columns != target_variable]\n",
    "# Select the data for the features\n",
    "X = df4[features]\n",
    "# Select the data for the target variable\n",
    "y = df4[target_variable]\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKK_JLNSmiYE"
   },
   "source": [
    "## Modeling: Decision Tree\n",
    "\n",
    "Finally, here's a simple example of how to ***build*** and visualize a decision-tree model (which is a specific type of machine learning model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "MWEAjfYnmi69",
    "outputId": "c5cb9dcf-db4f-41ab-f642-70ebd7651c9c"
   },
   "outputs": [],
   "source": [
    "# This imports the library that contains the code to build a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# This imports the function to visualize the tree\n",
    "from sklearn.tree import plot_tree\n",
    "# This imports a general library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the paramaters for building the model (e.g., max depth of 3)\n",
    "tree_model = DecisionTreeClassifier(max_depth=3)\n",
    "# Build a decision tree model based on historical data of whom survived the Titanic\n",
    "tree_model = tree_model.fit(X, y)\n",
    "# Set size of tree figure to be displayed\n",
    "plt.figure(figsize=(22,10))\n",
    "# Visualize the decision tree\n",
    "t = plot_tree(tree_model, fontsize=16, feature_names=features, filled=True,\n",
    "              impurity=False, class_names=[\"Dead!\", \"Alive!\"])\n",
    "# The visualization can be interpreted as follows:\n",
    "# - If the condition at the top is true, move left. Otherwise, move right.\n",
    "# - 'samples': Total number of individuals.\n",
    "# - 'value': Number of people that died (left) and survived (right).\n",
    "# - 'class': Predicted outcome for people at that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqmVuLsLFLdz"
   },
   "source": [
    "As you can see, the people more likely to survive are women (Sex_female > 0.5) who did not travel in third class (Pclass_3 < 0.5) and were more than 2.5 years old. On the other hand, the people more likely to die are men (Sex_female < 0.5) who were more than 6.5 years old and paid a low fare (Fare < 26.269).\n",
    "\n",
    "Note, however, that some nodes contain very few observations, which makes us wonder: are these nodes representive? How can we tell if this model is any good? How could we improve the model? We will analyze these (and many more other questions) as we advance in the course. But for now, let's look at how to ***use*** this model to make predictions.\n",
    "\n",
    "## Model Usage\n",
    "\n",
    "Below is a data set of people with an unknown survival status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "Z3J0YmyJFKpW",
    "outputId": "46dbe536-5c22-4be2-a0f6-a7f46b1d2946"
   },
   "outputs": [],
   "source": [
    "# Same as above, this code creates a dataframe using a CSV file stored in Google Drive\n",
    "\n",
    "df_unk1 = pd.read_csv(\"unknown_survival.csv\")\n",
    "print(f\"Total number of rows and columns: {df_unk1.shape}\")\n",
    "df_unk1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxwm-fiyIUOF"
   },
   "source": [
    "Note that this data set has exactly the same columns as the original data set we loaded, except for one: this data set does not contain the 'Survival' column. Fortunately, we could use our decision-tree model to predict how likely were these passengers to survive the Titanic (based on their features). But first, we need to do the data pre-processing for this data set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjwdy4LeBjAG",
    "outputId": "7101cb4c-75ba-4df6-95d6-538e761d7647"
   },
   "outputs": [],
   "source": [
    "cols = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
    "X2 = pd.get_dummies(df_unk1[cols], columns=['Pclass', 'Sex', 'Embarked'], drop_first=True)\n",
    "print(\"Number of passengers with missing values for each column:\")\n",
    "print(X2.isna().sum())\n",
    "\n",
    "# In this case, we will replace missing values with the mean, so that we can \n",
    "# make predictions for all passengers. Do you think this make sense? Why yes or \n",
    "# why not? If you want to share your thoughts, please feel free to post your \n",
    "# answer in the discussion board (this counts as class participation).\n",
    "X2['Age'] = X2['Age'].fillna(X2['Age'].mean())\n",
    "X2['Fare'] = X2['Fare'].fillna(X2['Fare'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf6CmdHHMvy_"
   },
   "source": [
    "Now that the data is pre-processed, we can use the decision tree to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "CjOje2HMK6dl",
    "outputId": "8b7122b4-08a9-4e2a-db3c-805cf11b95b6"
   },
   "outputs": [],
   "source": [
    "# Predict whether the person survived\n",
    "df_unk1[\"SurvivalPrediction\"] = tree_model.predict(X2)\n",
    "# Predict the probability of survival for this person\n",
    "df_unk1[\"SurvivalProbability\"] = tree_model.predict_proba(X2)[:, 1]\n",
    "df_unk1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64tIM41QNRz8"
   },
   "source": [
    "And done! This is how you build a predictive model and use it to make predictions. Simple, right?\n",
    "\n",
    "## Modeling: Logistic Regression\n",
    "\n",
    "So, what if you would like to build a logistic regression model instead? Well, it's very easy. You just import the library that includes the code for the LogisticRegression, and replace the line `model=DecisionTreeClassifier()` with `model=LogisticRegression()`. It's that simple! Here's an illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the code for the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# This code builds the logistic regression model (ignore the solver parameter for)\n",
    "logistic_model = LogisticRegression(solver='liblinear')\n",
    "logistic_model = logistic_model.fit(X, y)\n",
    "\n",
    "# This code makes the predictions\n",
    "df_unk1[\"SurvivalPrediction\"] = logistic_model.predict(X2)\n",
    "df_unk1[\"SurvivalProbability\"] = logistic_model.predict_proba(X2)[:, 1]\n",
    "df_unk1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the coefficients for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logistic_model.coef_, columns=X.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It conveys similar results to the tree: you are less likely to survive if you are older, female, or didn't pay for an expensive ticket or a fancy passenger class."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Lab1-IntroToDataScience.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
